Info on early career and/or young faculty awards

### Opportunity list
* [doe-os ecr: 2015](#meeting-doe-os-2016)
* [nasa ecf: 2015](#meeting-nasa-2015)
* [darpa yfa: 2015](#meeting-darpa-2015)

***

### doe-os ecr: doe-os-2015
[http://science.energy.gov/early-career/](http://science.energy.gov/early-career/)


### nasa ecf: nasa-2015
[http://nspires.nasaprs.com/external/solicitations/summary.do?method=init&solId={7A148E0E-4834-3C10-BADB-0C5060C4F961}&path=init](http://nspires.nasaprs.com/external/solicitations/summary.do?method=init&solId={7A148E0E-4834-3C10-BADB-0C5060C4F961}&path=init)

### darpa yfa: darpa-2015

Administrivia
* two 12-month segments of max $250k/year; optional extension of another year at up to $500k ("Director's Fellowship")
* within first 5 years in a tenure-track position; max of 3 applications
* there are a bunch of visits they want you to go on; include that in the budget
* 12 point font, except tables and figures
* page limits include figs, tables, charts. 
Bibliography and up to 3 relevant papers are not included in page limit. 
* the meat has an 8 page limit.

* Due April 13

Topic areas (questions to [DARPA-RA-15-32@darpa.mil](DARPA-RA-15-32@darpa.mil))

On npage 17, Technical Area Twenty Two: _New Theoretical Approaches to High-Dimensional
Optimization_: DARPA seeks theoretical research into new technical approaches to
convex and non-convex optimization for large (terabyte scale) and extremely high
dimensional datasets. As the DoD’s ability to collect data continues to grow with the
availability of cheap storage and small, affordable and deployable sensors, the gap
between data acquisition and analysis will continue to grow unless a more comprehensive
theoretical approach to optimization is developed.

Current approaches to large scale optimization and machine learning are bottlenecked by:
• Non-convex objective functions, and exponentially or high degree polynomial
scaling algorithms.
• Algorithms which are not optimized for parallelization and large scale
implementation.
• Poor understanding of heuristic and relaxation approaches for high dimensional
approximation.
• Algorithms not optimized for the known structure of datasets (long tailed degree
distributions, lack of medium scale clustering, etc.)

Recent advances in optimization have suggested that it might be possible to execute
terabyte scale problems in a mission actionable time. This topic seeks to leverage these
advances to discover new theoretical approaches to algorithmic construction. Focus areas
include, but are not limited to:
• Optimization algorithmic design tailored to large scale parallel implementations.
• Stochastic preconditioning and other randomized approaches enabling the
breaking of classical theoretical scaling ceilings.
• Convex relaxations of non-convex problems and a complete mathematical
understanding of the relationship between exact and relaxed objective functions.
• The leveraging of prior dataset knowledge for algorithmic speedup.
• Higher risk approaches such as numerical algebraic geometry.
